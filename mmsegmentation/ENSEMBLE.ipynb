{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17363e3a-2960-4b97-abeb-4f84c4e8856c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mmcv\n",
    "\n",
    "from mmcv import Config\n",
    "from mmseg.datasets import build_dataloader, build_dataset\n",
    "from mmseg.models import build_segmentor\n",
    "from mmseg.apis import single_gpu_test\n",
    "from mmcv.runner import load_checkpoint\n",
    "from mmcv.parallel import MMDataParallel\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import cv2\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a8fae86-da40-45bb-85b3-fecd165abf86",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_names = [\n",
    "    '/opt/ml/segmentation/mmsegmentation/work_dirs/05_upernet_final0/upernet_beit_large_all.py',\n",
    "    '/opt/ml/segmentation/mmsegmentation/work_dirs/11_segformer_swin_mixed0/11_segformer_swin_large_mixed_aug_all.py',\n",
    "    '/opt/ml/segmentation/mmsegmentation/work_dirs/12_segformer_swin_all0/12_segformer_swin_large.py',\n",
    "]\n",
    "checkpoint_pathes = [\n",
    "    '/opt/ml/segmentation/mmsegmentation//work_dirs/05_upernet_final0/best_mIoU_epoch_14.pth',\n",
    "    '/opt/ml/segmentation/mmsegmentation//work_dirs/11_segformer_swin_mixed0/best_mIoU_epoch_18.pth',\n",
    "    '/opt/ml/segmentation/mmsegmentation//work_dirs/12_segformer_swin_all0/best_mIoU_epoch_18.pth'\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2ea700c-69b1-496b-a007-51e340f55920",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-04 09:35:49,358 - mmseg - INFO - Loaded 819 images\n"
     ]
    }
   ],
   "source": [
    "cfg = Config.fromfile(config_names[0])\n",
    "# config file 들고오기\n",
    "root= '/opt/ml/segmentation/input/data/mmseg/test'\n",
    "\n",
    "# dataset config 수정\n",
    "cfg.data.test.img_dir = root\n",
    "cfg.data.test.pipeline[1]['img_scale'] = [(448, 448), (512, 512), (576, 576), \n",
    "                                          (640, 640), (704, 704), (768, 768)]\n",
    "cfg.data.test.pipeline[1]['flip'] = True\n",
    "cfg.data.test.test_mode = True\n",
    "\n",
    "cfg.data.samples_per_gpu = 4\n",
    "\n",
    "\n",
    "dataset = build_dataset(cfg.data.test)\n",
    "data_loader = build_dataloader(\n",
    "        dataset,\n",
    "        samples_per_gpu=1,\n",
    "        workers_per_gpu=cfg.data.workers_per_gpu,\n",
    "        dist=False,\n",
    "        shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "369adac3-3db5-402a-a34c-f7d3f80b15a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use load_from_local loader\n",
      "Use load_from_local loader\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "for config_name, checkpoint_path in zip(config_names, checkpoint_pathes):\n",
    "    cfg = Config.fromfile(config_name)\n",
    "    model = build_segmentor(cfg.model, test_cfg=cfg.get('test_cfg'))\n",
    "    checkpoint = load_checkpoint(model, checkpoint_path, map_location='cpu')\n",
    "\n",
    "    model.CLASSES = dataset.CLASSES\n",
    "    model.eval();\n",
    "    model = model.to('cuda')\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59e9a5b2-a86d-4133-b66a-55363fdf2bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/segmentation/lib/python3.7/site-packages/ipykernel_launcher.py:13: DeprecationWarning: `np.long` is a deprecated alias for `np.compat.long`. To silence this warning, use `np.compat.long` by itself. In the likely event your code does not need to work on Python 2 you can use the builtin `int` for which `np.compat.long` is itself an alias. Doing this will not modify any behaviour and is safe. When replacing `np.long`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  del sys.path[0]\n",
      "  0%|          | 0/819 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start prediction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 819/819 [16:33<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "End prediction.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import cv2\n",
    "import os\n",
    "import albumentations as A\n",
    "\n",
    "size = 256\n",
    "transform = A.Compose([A.Resize(size, size)])\n",
    "print('Start prediction.')\n",
    "\n",
    "file_name_list = []\n",
    "preds_array = np.empty((0, size*size), dtype=np.long)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    for step, data in enumerate(tqdm(data_loader)):\n",
    "        softs = []\n",
    "        for model_i , model in enumerate(models):\n",
    "            if model_i == 0 :\n",
    "                imgs = [d.to('cuda') for d in data['img'][:2]]\n",
    "                img_metas = [d.data[0] for d in data['img_metas'][:2]]\n",
    "            else :\n",
    "                imgs = [d.to('cuda') for d in data['img']]\n",
    "                img_metas = [d.data[0] for d in data['img_metas']]\n",
    "                    \n",
    "            logit = model(imgs,img_metas,return_loss=False)\n",
    "            soft = F.softmax(logit, dim=1).detach().cpu().numpy().astype(np.float16)\n",
    "            softs.append(soft)\n",
    "        soft_sum = sum(softs)\n",
    "        oms = np.argmax(soft_sum,1)\n",
    "        \n",
    "        # resize (256 x 256)\n",
    "        temp_mask = []\n",
    "        for img, mask in zip(np.stack(imgs[0].detach().cpu().numpy()), oms):\n",
    "            transformed = transform(image=img, mask=mask)\n",
    "            mask = transformed['mask']\n",
    "            temp_mask.append(mask)\n",
    "\n",
    "        oms = np.array(temp_mask)\n",
    "\n",
    "        oms = oms.reshape([oms.shape[0], size*size]).astype(int)\n",
    "        preds_array = np.vstack((preds_array, oms))\n",
    "\n",
    "print(\"End prediction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d051cdda-24ef-4c51-8dd9-73c81894399a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_submisson.csv 열기\n",
    "submission = pd.DataFrame({\"image_id\":[],\"PredictionString\":[]})\n",
    "json_dir = os.path.join(\"../input/data/test.json\")\n",
    "with open(json_dir, \"r\", encoding=\"utf8\") as outfile:\n",
    "    datas = json.load(outfile)\n",
    "\n",
    "# PredictionString 대입\n",
    "for image_id, predict in enumerate(preds_array):\n",
    "    image_id = datas[\"images\"][image_id]\n",
    "    file_name = image_id[\"file_name\"]\n",
    "    \n",
    "    submission = submission.append({\"image_id\" : file_name, \"PredictionString\" : ' '.join(str(e) for e in predict.tolist())}, \n",
    "                                   ignore_index=True)\n",
    "\n",
    "# submission.csv로 저장\n",
    "submission.to_csv(os.path.join('/opt/ml/segmentation', 'ensemble.csv'), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
